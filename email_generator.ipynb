{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eccd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce81968-0abb-4368-8cc2-ed28831cc153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.2.14\n",
      "  Using cached langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "Collecting langchain-community==0.2.12\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "Collecting langchain-groq===0.1.9\n",
      "  Using cached langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
      "Collecting unstructured==0.14.6\n",
      "  Using cached unstructured-0.14.6-py3-none-any.whl (2.0 MB)\n",
      "Collecting selenium==4.21.0\n",
      "  Using cached selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting chromadb==0.5.0\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "Collecting streamlit==1.35.0\n",
      "  Using cached streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting pandas==2.0.2\n",
      "  Using cached pandas-2.0.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Collecting python-dotenv==1.0.0\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python311\\lib\\site-packages (from langchain==0.2.14->-r requirements.txt (line 1)) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.11.6-cp311-cp311-win_amd64.whl (440 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.32\n",
      "  Using cached langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Using cached langsmith-0.1.144-py3-none-any.whl (310 kB)\n",
      "Collecting numpy<2,>=1\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached pydantic-2.10.0-py3-none-any.whl (454 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain==0.2.14->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting groq<1,>=0.4.1\n",
      "  Using cached groq-0.12.0-py3-none-any.whl (108 kB)\n",
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: filetype in c:\\python311\\lib\\site-packages (from unstructured==0.14.6->-r requirements.txt (line 4)) (1.2.0)\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.3.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python311\\lib\\site-packages (from unstructured==0.14.6->-r requirements.txt (line 4)) (4.12.3)\n",
      "Collecting emoji\n",
      "  Using cached emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "Collecting python-iso639\n",
      "  Using cached python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.10.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Collecting backoff\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\python311\\lib\\site-packages (from unstructured==0.14.6->-r requirements.txt (line 4)) (4.12.2)\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.27.0-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: wrapt in c:\\python311\\lib\\site-packages (from unstructured==0.14.6->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from unstructured==0.14.6->-r requirements.txt (line 4)) (4.67.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\python311\\lib\\site-packages (from selenium==4.21.0->-r requirements.txt (line 5)) (2.2.3)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\python311\\lib\\site-packages (from selenium==4.21.0->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Collecting build>=1.0.3\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting chroma-hnswlib==0.7.3\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Collecting fastapi>=0.95.2\n",
      "  Using cached fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Using cached uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Collecting posthog>=2.4.0\n",
      "  Using cached posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.20.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Using cached tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\python311\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 6)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\python311\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 6)) (7.7.0)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Using cached grpcio-1.68.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Using cached bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Using cached typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Collecting mmh3>=4.0.1\n",
      "  Using cached mmh3-5.0.1-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Collecting orjson>=3.9.12\n",
      "  Using cached orjson-3.10.11-cp311-none-win_amd64.whl (136 kB)\n",
      "Collecting altair<6,>=4.0\n",
      "  Using cached altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting click<9,>=7.0\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in c:\\python311\\lib\\site-packages (from streamlit==1.35.0->-r requirements.txt (line 7)) (24.2)\n",
      "Collecting pillow<11,>=7.1.0\n",
      "  Using cached pillow-10.4.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Collecting pyarrow>=7.0\n",
      "  Using cached pyarrow-18.0.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\python311\\lib\\site-packages (from streamlit==1.35.0->-r requirements.txt (line 7)) (6.4.1)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\python311\\lib\\site-packages (from streamlit==1.35.0->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python311\\lib\\site-packages (from pandas==2.0.2->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas==2.0.2->-r requirements.txt (line 8)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas==2.0.2->-r requirements.txt (line 8)) (2024.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 1)) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.17.2-cp311-cp311-win_amd64.whl (90 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (4.23.0)\n",
      "Collecting narwhals>=1.5.2\n",
      "  Using cached narwhals-1.14.1-py3-none-any.whl (220 kB)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from build>=1.0.3->chromadb==0.5.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq===0.1.9->-r requirements.txt (line 3)) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq===0.1.9->-r requirements.txt (line 3)) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq===0.1.9->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Using cached google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 6)) (1.8.0)\n",
      "Collecting requests-oauthlib\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 6)) (0.9)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 6)) (24.3.25)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Collecting deprecated>=1.2.6\n",
      "  Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.28.2\n",
      "  Using cached opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-common to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.28.1\n",
      "  Using cached opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.28.0\n",
      "  Using cached opentelemetry_proto-1.28.0-py3-none-any.whl (55 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.27.0\n",
      "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2\n",
      "  Using cached opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2\n",
      "  Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2\n",
      "  Using cached opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Collecting asgiref~=3.0\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-util-http to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opentelemetry-semantic-conventions to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opentelemetry-instrumentation-asgi to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opentelemetry-instrumentation to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl (12 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1\n",
      "  Using cached opentelemetry_instrumentation-0.49b1-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1\n",
      "  Using cached opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1\n",
      "  Using cached opentelemetry_util_http-0.49b1-py3-none-any.whl (6.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-api to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl (12 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0\n",
      "  Using cached opentelemetry_instrumentation-0.49b0-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0\n",
      "  Using cached opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl (159 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0\n",
      "  Using cached opentelemetry_util_http-0.49b0-py3-none-any.whl (6.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.28.0-py3-none-any.whl (64 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0\n",
      "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0\n",
      "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\python311\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 6)) (65.5.0)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.5.0->-r requirements.txt (line 6)) (1.6)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.0\n",
      "  Using cached pydantic_core-2.27.0-cp311-none-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.2.14->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.2.14->-r requirements.txt (line 1)) (3.10)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.35.0->-r requirements.txt (line 7)) (2.18.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (2.4.0)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium==4.21.0->-r requirements.txt (line 5)) (1.2.0)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirements.txt (line 6)) (0.14.0)\n",
      "Collecting httptools>=0.6.3\n",
      "  Using cached httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl (277 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirements.txt (line 6)) (14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python311\\lib\\site-packages (from beautifulsoup4->unstructured==0.14.6->-r requirements.txt (line 4)) (2.6)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Collecting cryptography>=3.1\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0\n",
      "  Using cached eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\python311\\lib\\site-packages (from unstructured-client->unstructured==0.14.6->-r requirements.txt (line 4)) (1.6.0)\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Collecting pypdf>=4.0\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.26.2-py3-none-any.whl (59 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
      "  Using cached pydantic-2.9.0-py3-none-any.whl (434 kB)\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.26.1-py3-none-any.whl (60 kB)\n",
      "  Using cached unstructured_client-0.26.0-py3-none-any.whl (59 kB)\n",
      "  Using cached unstructured_client-0.25.9-py3-none-any.whl (45 kB)\n",
      "Collecting deepdiff>=6.0\n",
      "  Using cached deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
      "Collecting mypy-extensions>=1.0.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: pycparser in c:\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (2.22)\n",
      "Collecting orderly-set==5.2.2\n",
      "  Using cached orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq===0.1.9->-r requirements.txt (line 3)) (1.0.7)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python311\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 6)) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain==0.2.14->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 7)) (0.21.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: toml, tenacity, tabulate, sympy, smmap, shellingham, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pysocks, pyreadline3, pyproject_hooks, pypdf, pydantic-core, pyasn1, pyarrow, protobuf, propcache, pillow, outcome, orjson, orderly-set, opentelemetry-util-http, oauthlib, numpy, narwhals, mypy-extensions, multidict, mmh3, mdurl, marshmallow, lxml, langdetect, jsonpath-python, jsonpatch, joblib, importlib-resources, importlib-metadata, httptools, grpcio, greenlet, fsspec, frozenlist, filelock, emoji, distro, deprecated, click, chardet, cachetools, blinker, bcrypt, backoff, asgiref, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, typing-inspect, trio, starlette, SQLAlchemy, rsa, requests-toolbelt, requests-oauthlib, pydeck, pydantic, pyasn1-modules, posthog, pandas, opentelemetry-proto, opentelemetry-api, nltk, markdown-it-py, humanfriendly, huggingface-hub, googleapis-common-protos, gitdb, deepdiff, cryptography, chroma-hnswlib, build, aiosignal, trio-websocket, tokenizers, rich, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, langsmith, groq, google-auth, gitpython, fastapi, dataclasses-json, coloredlogs, aiohttp, unstructured-client, typer, selenium, opentelemetry-sdk, opentelemetry-instrumentation-asgi, onnxruntime, langchain-core, kubernetes, altair, unstructured, streamlit, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-groq, langchain, chromadb, langchain-community\n",
      "  Running setup.py install for langdetect: started\n",
      "  Running setup.py install for langdetect: finished with status 'done'\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.6 aiosignal-1.3.1 altair-5.4.1 annotated-types-0.7.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 blinker-1.9.0 build-1.2.2.post1 cachetools-5.5.0 chardet-5.2.0 chroma-hnswlib-0.7.3 chromadb-0.5.0 click-8.1.7 coloredlogs-15.0.1 cryptography-43.0.3 dataclasses-json-0.6.7 deepdiff-8.0.1 deprecated-1.2.15 distro-1.9.0 emoji-2.14.0 fastapi-0.115.5 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.10.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.36.0 googleapis-common-protos-1.66.0 greenlet-3.1.1 groq-0.12.0 grpcio-1.68.0 httptools-0.6.4 huggingface-hub-0.26.2 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 joblib-1.4.2 jsonpatch-1.33 jsonpath-python-1.0.6 kubernetes-31.0.0 langchain-0.2.14 langchain-community-0.2.12 langchain-core-0.2.43 langchain-groq-0.1.9 langchain-text-splitters-0.2.4 langdetect-1.0.9 langsmith-0.1.144 lxml-5.3.0 markdown-it-py-3.0.0 marshmallow-3.23.1 mdurl-0.1.2 mmh3-5.0.1 multidict-6.1.0 mypy-extensions-1.0.0 narwhals-1.14.1 nltk-3.9.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orderly-set-5.2.2 orjson-3.10.11 outcome-1.3.0.post0 pandas-2.0.2 pillow-10.4.0 posthog-3.7.2 propcache-0.2.0 protobuf-4.25.5 pyarrow-18.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.0 pydantic-core-2.27.0 pydeck-0.9.1 pypdf-5.1.0 pyproject_hooks-1.2.0 pyreadline3-3.5.4 pysocks-1.7.1 python-dotenv-1.0.0 python-iso639-2024.10.22 python-magic-0.4.27 rapidfuzz-3.10.1 regex-2024.11.6 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 rsa-4.9 selenium-4.21.0 shellingham-1.5.4 smmap-5.0.1 starlette-0.41.3 streamlit-1.35.0 sympy-1.13.3 tabulate-0.9.0 tenacity-8.5.0 tokenizers-0.20.3 toml-0.10.2 trio-0.27.0 trio-websocket-0.11.1 typer-0.13.1 typing-inspect-0.9.0 unstructured-0.14.6 unstructured-client-0.25.9 uvicorn-0.32.1 watchfiles-0.24.0 yarl-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: langdetect is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16ff50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped onto the lunar surface on July 20, 1969, as part of the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.1-70b-versatile\"\n",
    ")\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d33612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Victoria’s Secret - Job Description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Our CultureBenefitsOur BrandsJob AreasCorporateDistribution CentersStoresEarly TalentFAQsJob Search\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Director Data Sciences & Analytics – Victoria’s Secret Careers – 0443Wnbowman2024-06-12T12:18:01+00:00\n",
      "\n",
      "\n",
      "0443W\n",
      "\n",
      "\n",
      "< Back to search results  Director Data Sciences & Analytics Brand: Victoria's Secret Location: Bangalore, Karnataka, IN Job Area: Digital Employment type: Full-time Job ID: 0443W  Description   TITLE: Director – Data Science & AnalyticsDEPARTMENT: Data Sciences & AnalyticsLOCATION: Bangalore, India TEAM: The Enterprise Data Sciences & Analytics is an upstart CoE team, incubated within Victoria’ Secret & CO. (VS&Co), building the best-in-class suite of Data Science & Analytics Products that power the best shopping experience for our customers, and deliver actionable, customer-centric insights to our ecommerce, marketing, merchandising and supply chain teams enabling better business decisions on omni channel (digital + store) 360 performances. PURPOSE :The Director – Data Science & Analytics will be leading a team of data scientists & analysts partnering with business stakeholders and product owners to deliver outstanding business outcomes for problems across VS&Co:• You will be leading teams that develops and productizes machine learning models on: i. customer segmentations & propensity models, ii. A/B testing, measurement frameworks & Causal modelling, iii. NLP, LLMs & embeddings, GenAI chat-bots, iv. time-series forecasting & anomaly detection, v. optimization and recommendation systems.• You have a deep interest and passion for technology. You love innovation and enjoy working with people motivating them to strive for better outcomes at every stage. • You have strong problem solving, analytic, decision-making, and excellent communication with interpersonal skills. You are self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities.• You will work directly on the AI problems that have the most impact on VS&Co’s digital ecommerce, omni-channel, entire supply chain, forecasting and merchandising. RESPONSIBILITIES • Coaching and developing high-performance team: Lead several teams of data scientists and engineers to ensure business deliverables are met. Train, develop and coach managers and individual contributors on technical and professional skills.• Hire, train, and supervise India based data scientists & analysts and ensure delivery of right analytical solutions to business questions. • Business Thought Partnership: Provide thought leadership and counsel to stakeholders in exploring possible data science solutions to address business questions and business needs. • Define problem statement. • Translate business requirements into data science / analytic strategies, initiatives, and projects, align them to business team’s strategy and objectives. • Synthesize data from different sources, provide actionable business insights and / or analytic solution to stakeholders.• Collaborate and implement the overall analytics strategy. Evaluate, recommend, implement and maintain data science & analytical tools• Technical leadership for data science & analytic community: Develop expertise and Train / coach associates on technical knowledge of the respective data domains to deliver analytic solutions / insights for business stakeholders.• Identify, validate and create new opportunities/experiences through data analysis & use of advanced analytics & data sciences. Implement solutions that optimize business processes, improve our ongoing marketing and product operations, and develop new revenue drivers and cost savings. • Deliver analytics COE services & projects from India    Qualifications  EDUCATION• B.S. degree in Computer Science, Mathematics, Statistics• M.S. or PH.D. in Computer Science, applied mathematics, statistics, physics, operations research, quantitative social sciences or related fields will be preferred SKILLS / EXPERIENCE• 12+ years of relevant experience in data scientist & analytics role preferably in retail domain. 5+ years in a leadership role• Demonstrated history of technology leadership and strong hands-on experience• Proven records of scientific publications or intellectual property generation• Experience in strong programming skills across big data and ML engineering stack• Experience in leading & mentoring a team of data scientists & building relevant capabilities• Track record in managing deliveries of advanced analytical solutions in an agile & iterative model• Experience in retail is an added plus (especially retail customer domain)• Experience in GenAI is an added plus.  PERSONAL CHARACTERISTICS• We love open source! Many of our team members contribute to open source communities and get to do it during work time. We try to contribute back to our communities where we can and are grateful to be able to open source some of our own projects!• Unique individuals that are innovators• Highly energized personality with a positive attitude and ability to work with minimal supervision, prioritize, multitask, and work under tight timelines.• Intellectually curious• Identify and present obscure data that is unique and useful.• Genuinely interested in data and how data can drive returns.• Stays current with business results, strategies, industry standards and best practices especially in the field of data sciences & machine learning.• Professional demeanor• Able to present, communicate, and is approachable by business executives.• Has self-reliance and uses good common sense.• Build strong relationships and build out network with peers and data providers.• Organized and able to present ideas.• Strong Work Ethic. Assertive yet willing to work within a team and take on any task.• We value diversity. We believe that diversity and inclusion is of core importance when try to create positive in-store experiences for our guests, and we think it is also critically important when building our teams. Read more about our commitment to diversity and inclusionMANDATORY SKILLS :• Machine Learning, Python, Big Data Skills, R, Statistics• Solid experience working with state-of-the-art supervised and unsupervised machine learning algorithms on real-world problems, preferably in ecommerce and retail domains.• Strong ability to understand the business and good stakeholder management capabilities and has mentored data scientists in developing ML solutions.   Apply  SHARE THIS ENTRYJOBS YOU MAY LIKECustomer Experience Lead-The Woodlands Mall VSThe Woodlands, TXCustomer Experience Lead-The Woodlands Mall VSThe Woodlands, TXStore Manager - Victoria's Secret - Park Meadows - Littleton, COLittleton, COSelling Associate-West RoadsOmaha, NECustomer Experience Lead-EmpireSioux Falls, SD\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "OUR CULTUREOUR BRANDSJOB AREASINTERNSHIPSFAQs\n",
      "4 Limited Pkwy,\n",
      "Reynoldsburg, OH 43068\n",
      "ACCESSIBILITY ASSISTANCEIf you require assistance or an accommodation due to a disability, please call 877-415-7170 or email applicantaccommodations@victoria.com. A Victoria’s Secret associate will respond to your message as soon as reasonably possible.\n",
      "\n",
      "Victoria’s Secret & Co. Corporate\n",
      "Policies\n",
      "Privacy policy\n",
      "Do Not Sell or Share My personal Information\n",
      "Supply Chain\n",
      "Terms and Conditions\n",
      "Contact Us\n",
      "Website Accessibility\n",
      "© 2024 Victoria’s Secret. All Rights Reserved.\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "Page load link\n",
      "\n",
      "\n",
      "<!--<script>\n",
      "var intervalrunningno = 0;\n",
      "if (localStorage.getItem(\"notifyBannerShownOnce\") === null) {\n",
      "var changeAcceptTextEU = setInterval(function () {  \n",
      "    \n",
      "\tvar checkEUStatus = CookieControl.geoInfo(); \n",
      "\tif(!checkEUStatus.withinEU){\n",
      "\t\tif($('#ccc #ccc-notify.ccc-notify__top button#ccc-notify-accept > span').text() == 'Accept'){\n",
      "\t\t\t$('#ccc #ccc-notify.ccc-notify__top button#ccc-notify-accept > span').html('OK')\n",
      "\t\t\tcheckEUStatusChanged = \"true\";\n",
      "          localStorage.setItem(\"notifyBannerShownOnce\", true);\n",
      "\t\t}\n",
      "\t\tif($('#ccc #ccc-notify.ccc-notify__top button#ccc-notify-accept > span').text() == 'OK') {        \n",
      "\t\t\tclearInterval(changeAcceptTextEU);\n",
      "\t\t} \n",
      "      if (localStorage.getItem(\"notifyBannerShownOnce\") == 'true'){\n",
      "      clearInterval(changeAcceptTextEU);\n",
      "      }\n",
      "\t} else {\n",
      "\t\tclearInterval(changeAcceptTextEU);\n",
      "\t}\n",
      "\n",
      "}, 100); \n",
      "}\n",
      " --!>\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Go to Top\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://careers.victoriassecret.com/en/job/21010573/director-data-sciences-analytics-bangalore-in/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c89a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "026cbe70-ca0b-43fc-9158-4341c51f2af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"role\": \"Director Data Sciences & Analytics\",\\n    \"experience\": \"12+ years of relevant experience in data scientist & analytics role preferably in retail domain. 5+ years in a leadership role\",\\n    \"skills\": [\\n      \"Machine Learning\",\\n      \"Python\",\\n      \"Big Data Skills\",\\n      \"R\",\\n      \"Statistics\"\\n    ],\\n    \"description\": \"The Director – Data Science & Analytics will be leading a team of data scientists & analysts partnering with business stakeholders and product owners to deliver outstanding business outcomes for problems across VS&Co.\"\\n  }\\n]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5415fd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'Director Data Sciences & Analytics',\n",
       "  'experience': '12+ years of relevant experience in data scientist & analytics role preferably in retail domain. 5+ years in a leadership role',\n",
       "  'skills': ['Machine Learning',\n",
       "   'Python',\n",
       "   'Big Data Skills',\n",
       "   'R',\n",
       "   'Statistics'],\n",
       "  'description': 'The Director – Data Science & Analytics will be leading a team of data scientists & analysts partnering with business stakeholders and product owners to deliver outstanding business outcomes for problems across VS&Co.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# json_parser = JsonOutputParser()\n",
    "# json_res = json_parser.parse(res.content)\n",
    "# json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73f32867-3296-4d76-bcec-544ab218f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Parse the response\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "\n",
    "# Convert list to dictionary\n",
    "if isinstance(json_res, list) and len(json_res) == 1:  # Ensure it has only one dictionary\n",
    "    json_res = json_res[0]  # Extract the first item\n",
    "else:\n",
    "    raise ValueError(\"Expected a list with a single dictionary.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39961ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf930fa6-6034-495d-9119-ffc906d6ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning', 'Python', 'Big Data Skills', 'R', 'Statistics']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = json_res\n",
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e8a0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Techstack</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angular,.NET, SQL Server</td>\n",
       "      <td>https://example.com/angular-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://example.com/vue-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://example.com/python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://example.com/java-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flutter, Firebase, GraphQL</td>\n",
       "      <td>https://example.com/flutter-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WordPress, PHP, MySQL</td>\n",
       "      <td>https://example.com/wordpress-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Magento, PHP, MySQL</td>\n",
       "      <td>https://example.com/magento-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>React Native, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-native-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iOS, Swift, Core Data</td>\n",
       "      <td>https://example.com/ios-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Android, Java, Room Persistence</td>\n",
       "      <td>https://example.com/android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kotlin, Android, Firebase</td>\n",
       "      <td>https://example.com/kotlin-android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Android TV, Kotlin, Android NDK</td>\n",
       "      <td>https://example.com/android-tv-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iOS, Swift, ARKit</td>\n",
       "      <td>https://example.com/ios-ar-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cross-platform, Xamarin, Azure</td>\n",
       "      <td>https://example.com/xamarin-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Backend, Kotlin, Spring Boot</td>\n",
       "      <td>https://example.com/kotlin-backend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frontend, TypeScript, Angular</td>\n",
       "      <td>https://example.com/typescript-frontend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full-stack, JavaScript, Express.js</td>\n",
       "      <td>https://example.com/full-stack-js-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Machine Learning, Python, TensorFlow</td>\n",
       "      <td>https://example.com/ml-python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DevOps, Jenkins, Docker</td>\n",
       "      <td>https://example.com/devops-portfolio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Techstack  \\\n",
       "0                React, Node.js, MongoDB   \n",
       "1               Angular,.NET, SQL Server   \n",
       "2      Vue.js, Ruby on Rails, PostgreSQL   \n",
       "3                  Python, Django, MySQL   \n",
       "4              Java, Spring Boot, Oracle   \n",
       "5             Flutter, Firebase, GraphQL   \n",
       "6                  WordPress, PHP, MySQL   \n",
       "7                    Magento, PHP, MySQL   \n",
       "8         React Native, Node.js, MongoDB   \n",
       "9                  iOS, Swift, Core Data   \n",
       "10       Android, Java, Room Persistence   \n",
       "11             Kotlin, Android, Firebase   \n",
       "12       Android TV, Kotlin, Android NDK   \n",
       "13                     iOS, Swift, ARKit   \n",
       "14        Cross-platform, Xamarin, Azure   \n",
       "15          Backend, Kotlin, Spring Boot   \n",
       "16         Frontend, TypeScript, Angular   \n",
       "17    Full-stack, JavaScript, Express.js   \n",
       "18  Machine Learning, Python, TensorFlow   \n",
       "19               DevOps, Jenkins, Docker   \n",
       "\n",
       "                                                Links  \n",
       "0                 https://example.com/react-portfolio  \n",
       "1               https://example.com/angular-portfolio  \n",
       "2                   https://example.com/vue-portfolio  \n",
       "3                https://example.com/python-portfolio  \n",
       "4                  https://example.com/java-portfolio  \n",
       "5               https://example.com/flutter-portfolio  \n",
       "6             https://example.com/wordpress-portfolio  \n",
       "7               https://example.com/magento-portfolio  \n",
       "8          https://example.com/react-native-portfolio  \n",
       "9                   https://example.com/ios-portfolio  \n",
       "10              https://example.com/android-portfolio  \n",
       "11       https://example.com/kotlin-android-portfolio  \n",
       "12           https://example.com/android-tv-portfolio  \n",
       "13               https://example.com/ios-ar-portfolio  \n",
       "14              https://example.com/xamarin-portfolio  \n",
       "15       https://example.com/kotlin-backend-portfolio  \n",
       "16  https://example.com/typescript-frontend-portfolio  \n",
       "17        https://example.com/full-stack-js-portfolio  \n",
       "18            https://example.com/ml-python-portfolio  \n",
       "19               https://example.com/devops-portfolio  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"my_portfolio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7e888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39ad2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/ios-portfolio'}],\n",
       " [{'links': 'https://example.com/android-tv-portfolio'},\n",
       "  {'links': 'https://example.com/java-portfolio'}],\n",
       " [{'links': 'https://example.com/ios-portfolio'},\n",
       "  {'links': 'https://example.com/ml-python-portfolio'}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bd36844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Director Data Sciences & Analytics',\n",
       " 'experience': '12+ years of relevant experience in data scientist & analytics role preferably in retail domain. 5+ years in a leadership role',\n",
       " 'skills': ['Machine Learning',\n",
       "  'Python',\n",
       "  'Big Data Skills',\n",
       "  'R',\n",
       "  'Statistics'],\n",
       " 'description': 'The Director – Data Science & Analytics will be leading a team of data scientists & analysts partnering with business stakeholders and product owners to deliver outstanding business outcomes for problems across VS&Co.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ccfd720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning', 'Python', 'Big Data Skills', 'R', 'Statistics']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job = json_res\n",
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a97dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Expert Data Science & Analytics Solutions for VS&Co.\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across the job description for the Director Data Sciences & Analytics role at VS&Co. and was impressed by the company's commitment to leveraging data-driven insights to drive business outcomes. As a Business Development Executive at AtliQ, I'd like to introduce our company as a potential partner in fulfilling your data science and analytics needs.\n",
      "\n",
      "AtliQ is an AI & Software Consulting company with a proven track record of delivering tailored solutions that foster scalability, process optimization, cost reduction, and heightened overall efficiency. Our team of experts has extensive experience in developing and implementing data science and analytics solutions, particularly in the retail domain.\n",
      "\n",
      "Our capabilities align perfectly with the skills required for the Director Data Sciences & Analytics role, including Machine Learning, Python, Big Data Skills, R, and Statistics. We've successfully executed projects that involve partnering with business stakeholders and product owners to deliver outstanding business outcomes.\n",
      "\n",
      "I'd like to highlight a few examples from our portfolio that demonstrate our expertise in data science and analytics:\n",
      "\n",
      "* Machine Learning and Python-based solutions: https://example.com/ml-python-portfolio\n",
      "* Python-based data analytics solutions: https://example.com/python-portfolio\n",
      "\n",
      "These projects showcase our ability to develop and implement data-driven solutions that drive business outcomes. I believe our team would be an excellent fit to support the Director Data Sciences & Analytics role and contribute to the success of VS&Co.\n",
      "\n",
      "If you're interested in learning more about our capabilities and how we can support your data science and analytics needs, I'd be happy to schedule a call to discuss further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Mohan\n",
      "Business Development Executive\n",
      "AtliQ\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
    "        the seamless integration of business processes through automated tools. \n",
    "        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability, \n",
    "        process optimization, cost reduction, and heightened overall efficiency. \n",
    "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ \n",
    "        in fulfilling their needs.\n",
    "        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
    "        Remember you are Mohan, BDE at AtliQ. \n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263ce23-a6fa-4029-a4ee-9c586d409cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
